---
title: "Confidence in Taxi Fares"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(mosaicCore)
library(mosaic)
knitr::opts_chunk$set(echo = TRUE)
load("Taxi_trips.rda")
Five_mile_trips <- 
  Taxi_trips %>%
  filter(4.5 < distance, distance < 5.5)
set.seed(101)
My_trips <- 
  Five_mile_trips %>%
  sample_n(size = 10)
```


## Background

It's often the case that we have to draw conclusions from a small set of observations. In this exercise, we'll look at what you can deduce about the price of a taxi trip from a handful of previous trips.

Imagine that you have saved the receipts from previous trips and want to use the information on them to to make a prediction about your next trip. Each trip you take is somewhat random even if it is always from and to the same places. For instance, traffic might be snarled or there might be construction or some other obstruction that causes a detour. Or any particular taxi driver might know a shortcut or might not know the best route to take.

For a classroom exercise, it would be inconvenient (and expensive) to send each member of the class on several taxi trips. Instead, we'll use a record of a large set of actual taxi trips collected by the New York City [Taxi and Limosine Commission](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml). So rather than going out to the street and hailing a cab, you'll have the computer draw a random trip from the Taxi Commission data.


## Your predicament

You have to go 5 miles, almost every evening. You want to have enough money, but this being New York you don't want to have much more than that. How much do you need to be sure that you can pay the fare? 

As you can imagine, the price of a taxi trip depends, among other things, on the *distance* travelled. The graph plots out the *fare* vs *distance* for every trip in the Taxi Commission data. A regular taxi rider knows the distance he or she is going to travel. The benefit of the graph format is that, knowing the distance, you can pick the appropriate place on the x-axis and then figure out the fare by tracing upwards to the dots.

```{r look0, exercise = TRUE}
Taxi_trips %>%
  gf_point(fare ~ distance, alpha = .04)
```

* For a trip of 10 miles, what's the fare? As you can see, there's a range of fares.
    - Find the smallest fare for a trip of 10 miles.
    - Find the largest fare for a trip of 10 miles.
    - Is the largest fare definite? That is, is there a clear top border to the cloud of dots for 10-mile trips? 
* How come the cloud of dots has a dark core in the lower left?

The graph above shows trips of many different distances. Your trip is 5 miles long, but as we said, due to traffic or detours or short-cuts, any day's trip might be a bit longer or shorter, say, from 4.5 to 5.5 miles. We've already run the computer instruction that follows. Its purpose is to collect all the instances of 4.5 to 5.5 mile trips from the Taxi Commissions `Taxi_trips` data, storing those instances under the name `Five_mile_trips`.

```{r eval=FALSE}
Five_mile_trips <- 
  Taxi_trips %>%
  filter(4.5 < distance, distance < 5.5)
```

There are `r nrow(Five_mile_trips)` records of the five-mile trips. With all that data, we can get a pretty good idea of the range and distribution of fares.

To familiarize youself with the data, look at a random sample of, say, 3 trips from the `Five_mile_trips` collection:

```{r five0, exercise = TRUE, exercise.setup = "five0"}
Five_mile_trips %>%
  sample_n(size = 3)
```

We'll generate your sample of 10 trips in just a minute, but let's take one more look at all the 5-mile trips in the Taxi Commission data. This graph shows the distribution of fares.

```{r five1, exercise = TRUE, exercise.setup = "five0"}
Five_mile_trips %>%
  gf_histogram( ~ fare, fill = "green", alpha = 0.4)
```

* Explain how the information in the above graph relates to the scatter plot that we made earlier of fare vs distance? Which of the dots in that scatter plot are presented in the histogram?

Obviously, the largest fare is much larger than the smallest. We can read this off the histogram or compute it directly.

```{r five2, exercise = TRUE, exercise.setup = "five0"}
Five_mile_trips %>%
  df_stats( ~ fare, min, max)
```

You might think that now you have *the* answer: To be sure you have enough money, take at least $`r format(global_max <- base::max(Five_mile_trips$fare), nsmall=2)` with you.

So why isn't this the end of the matter? Read on ...


## The real problem

You don't have all the data, just the data from your experience of 10 taxi rides.

To simulate your experience, which involved ten more-or-less random taxis picking you up on ten different days, let's take a random sample of size n=10.

```{r setseed, echo = FALSE}
set.seed(101)
```

```{r sample0, exercise = TRUE, exercise.setup="setseed"}
My_trips <- 
  Five_mile_trips %>%
  sample_n(size = 10)
My_trips
```

If you look down the column for the `fare` variable, you can identify which trip had the largest fare. Or, you can have the computer do this for you, as with the following computer instruction:

```{r max0, exercise = TRUE}
My_trips %>%
  df_stats( ~ fare, max)
```

You can see that the maximum fare you encountered in your sample is not as large as the `r format(global_max, nsmall = 2)` maximum fare for a 5-mile trip in the Taxi Commission data.


## A Distribution?

In thinking about things statistically, it's not enough just to look at the result from our particular sample of taxi trips. We also have to think about how that result might have varied. For instance, what would happen if we asked a friend to collect another sample of data? The result would presumably be somewhat different. Let's try: 

```{r friend, exercise = TRUE}
Five_mile_trips %>%
  sample_n(size = 10) %>%
  df_stats( ~ fare, max)
```

Each time you run the data-collection and analysis procedure in the previous box, you'll get a different result for the maximum fare. Try it a few times.

One way to think about how much confidence we can have in the result from our particular experience of ten rides is to look at the *distribution* of results from repeating the data collection and analysis many times. Computers make this very easy.

To illustrate, here the computer is being instructed to run the process three times, creating three different *trials* of the data collection and analysis.

```{r friend2, exercise=TRUE}
do(3) * {
  Five_mile_trips %>%
  sample_n(size = 10) %>%
  df_stats( ~ fare, max)
}
```

Looking at *many* trials, say 500, gives us a pretty good idea of how much our result might have varied. 

```{r friend3, exercise = TRUE}
Trials <-
  do(500) * {
    Five_mile_trips %>%
      sample_n(size = 10) %>%
      df_stats( ~ fare, max_fare = max)
  }
# Display how?
head(Trials)
Trials %>%
  gf_histogram( ~ max_fare)
Trials %>%
  df_stats(~ max_fare, mean, coverage(level = 0.95))
```

Remember, in each trial we did a complete simulation of collecting data on ten taxi rides and calculating the maximum fare. The point of doing all this work is to be able to see what the sampling distribution of the maximum fare looks like. And the point of looking at the sampling distribution is to judge whether your procedure --- sample ten taxi rides and find the maximum fare you paid --- is *adequate* for your purpose.

Here we can see two problems for our ten-ride method of estimating the maximum fare:

1. On average the result of our procedure will be too low. After all, in the complete taxi data, the actual maximum fare for a five-mile ride is $`r format(global_max, nsmall=2)`. In statistics, this sort of problem is called *bias*.
    * Looking at the display from the 500 trials, estimate the *difference* between the center of the distribution and the actual maximum fare.
2. There's a lot of spread in the result of our procedure, which means we have a lot of uncertainty about whether our particular result is close to the truth.
    * Looking again at the display of the 500 trials, how *wide* is the distribution?

So the answer we get from our sample of ten rides is imperfect. Whether it is *good enough* depends on what we plan to use the answer for. For instance, if we always have $10 extra on hand beyond our estimate of the maximum taxi fare, we'll be in good shape to pay the fare whatever it is likely to be.

One way to improve things is to *collect a larger sample*. 

3. Go back to the calculation of the 500 trials and change the sample size from n = 10 to n = 40. This will change both the bias and the width of the distribution. 
    * How much did the increase in sample size reduce the bias? 
    * How much did it reduce the width of the distribution?

## Just from the data?

The point of this exercise is to demonstrate sampling variation. Being able to find the sampling distribution of your result is key to understanding whether your result is good enough for your purposes.

In the real world, you need to estimate the sampling distribution without having access to data beyond your actual sample. So, rather than having the `r nrow(Five_mile_trips)` five-mile trips, we would need to make the estimate using just the few trips in our sample. Many of the statistical methods we will study address exactly this issue: how to use the sample itself to determine how confident you can be in your result.
